<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Neural Net Optimization, Part 1 — The Computational Graph | Eli C. McPherson </title> <meta name="author" content="Eli C. McPherson"> <meta name="description" content="The first in a four-part series exploring neural network optimization, starting from scratch with a toy computational graph and building up to scalable, practical ML systems."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ecm893.github.io/blog/2025/ml-levels-pt-one/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Neural Net Optimization, Part 1 — The Computational Graph",
            "description": "The first in a four-part series exploring neural network optimization, starting from scratch with a toy computational graph and building up to scalable, practical ML systems.",
            "published": "May 23, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Eli</span> C. McPherson </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Neural Net Optimization, Part 1 — The Computational Graph</h1> <p>The first in a four-part series exploring neural network optimization, starting from scratch with a toy computational graph and building up to scalable, practical ML systems.</p> </d-title> <d-article> <h1 id="in-the-beginning">In the Beginning</h1> <p>Welcome to the first post in a three-part series on neural network optimization! My goal is to share a practical perspective on how the scale and complexity of neural network optimization evolves, especially for those who, like me, started without much formal training. Over the years, I’ve helped several early-stage companies move from a handful of Jupyter notebooks to more robust, scalable ML workflows. This series chronicles that journey and the lessons learned along the way.</p> <h2 id="three-levels-of-neural-network-implementation">Three Levels of Neural Network Implementation</h2> <ol> <li> <p><strong>Computational Graph:</strong><br> A simple computational graph network, built from scratch, capable of a forward pass (post-order traversal) and auto-differentiation (backward pass) to fit any defined network to a set of data points.</p> </li> <li> <p><strong>PyTorch Example:</strong><br> A minimal PyTorch implementation, capable of more complex learning on a basic multilayer perceptron. This demonstrates how frameworks can simplify and scale up what’s possible.</p> </li> <li> <p><strong>Scaling Up:</strong><br> The real-world challenge: distributing training and tuning across multiple GPUs, or running many experiments in parallel on a single GPU.</p> </li> </ol> <hr> <h2 id="the-repository">The Repository</h2> <p>All code for this post is available on <a href="https://github.com/ECM893/computational_graph" rel="external nofollow noopener" target="_blank">GitHub</a>.</p> <hr> <h1 id="the-computational-graph">The Computational Graph</h1> <p>This is the third time in my life I’ve built this example from scratch, and I promise myself it’ll be the last! But it’s a fantastic way to understand the basics of neural networks, how they’re optimized, and why frameworks like PyTorch exist.</p> <p><strong>If you’ve ever wondered what’s happening “under the hood” in PyTorch or TensorFlow, this is it: at their core, these frameworks build and manipulate computational graphs just like this one—except they do it automatically, at scale, and with hardware acceleration. Every neural network you define in PyTorch is internally represented as a computational graph, where each operation (like addition, multiplication, or activation functions) becomes a node, and the framework handles the forward and backward passes for you.</strong></p> <p>The computational graph here is made from a few simple nodes (constants, inputs, addition, multiplication, and power). A graph object manages these nodes, letting us interact with the network as a whole rather than node-by-node.</p> <hr> <h2 id="why-this-is-hard-to-scale">Why This Is Hard to Scale</h2> <p>While building a computational graph from scratch is a great learning exercise, it quickly becomes impractical for real-world ML tasks, for two key reasons:</p> <h3 id="1-complexity-and-scalability">1. Complexity and Scalability</h3> <ul> <li> <strong>Manual Graph Construction:</strong><br> Every operation and connection must be explicitly defined. As our network grows, this becomes tedious and error-prone.</li> <li> <strong>No GPU Support:</strong><br> Hand-rolled computational graphs are CPU-bound and not designed for parallel computation. Scaling to larger models or datasets (let alone running on a GPU) is a massive challenge.</li> <li> <strong>Debugging:</strong><br> When things go wrong, it’s hard to tell if the issue is with our math, our code, or our hyperparameters.</li> </ul> <h3 id="2-the-hyperparameter-trap">2. The Hyperparameter Trap</h3> <ul> <li> <strong>Tuning Is Everything:</strong><br> Even if our code is mathematically correct, poor hyperparameter choices (like learning rate or gradient clipping) can make our model look broken — or make a working model look perfect. The difference between “Is there a bug in my code?” and “Wow, this works perfectly!” often comes down to just a few numbers.</li> </ul> <hr> <h2 id="example-fitting-a-polynomial">Example: Fitting a Polynomial</h2> <p>Take the example in my repository, <code class="language-plaintext highlighter-rouge">example_polynomial_fit.py</code>.<br> It fits a dataset of the form:</p> \[y = c_0 x_1^2 + c_1 x_1 + c_2 x_2^2 + c_3 x_2 + c_4\] <p>using a hand-built computational graph.</p> <hr> <h2 id="the-good-when-it-works">The Good: When It Works</h2> <p>With reasonable hyperparameters, the model converges smoothly:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MAX_GRAD</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">MIN_LR</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">LR_DECAY</span> <span class="o">=</span> <span class="mf">0.999</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.01</span>
</code></pre></div></div> <style>.responsive-iframe-container{position:relative;width:100%;max-width:100%;aspect-ratio:16 / 9;height:auto;overflow:hidden;min-height:300px}.responsive-iframe-container.box{aspect-ratio:1 / 1;min-height:250px}.responsive-iframe-container iframe{position:absolute;inset:0;width:100%;min-width:0;max-width:100%;height:100%;min-height:0;max-height:100%;border:0;display:block;overflow:hidden;background:transparent;box-sizing:border-box}@media(max-width:600px){.responsive-iframe-container{aspect-ratio:unset;min-height:220px;height:220px}.responsive-iframe-container.box{aspect-ratio:unset;min-height:180px;height:180px}}</style> <div class="responsive-iframe-container"> <iframe src="/assets/plotly/losses.html" allowfullscreen="" sandbox="allow-scripts allow-same-origin"></iframe> </div> <div class="responsive-iframe-container box"> <iframe src="/assets/plotly/model_surface.html" allowfullscreen="" sandbox="allow-scripts allow-same-origin"></iframe> </div> <hr> <h2 id="the-bad-when-it-doesnt">The Bad: When It Doesn’t</h2> <p>But with a bad learning rate (and uncapped gradients), the solution becomes unstable and never converges:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MAX_GRAD</span> <span class="o">=</span> <span class="mf">1e10</span>
<span class="n">MIN_LR</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">LR_DECAY</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.1</span>
</code></pre></div></div> <div class="responsive-iframe-container"> <iframe src="/assets/plotly/losses_bad.html" allowfullscreen="" sandbox="allow-scripts allow-same-origin"></iframe> </div> <div class="responsive-iframe-container box"> <iframe src="/assets/plotly/model_surface_bad.html" allowfullscreen="" sandbox="allow-scripts allow-same-origin"></iframe> </div> <hr> <h2 id="key-takeaways">Key Takeaways</h2> <ul> <li> <strong>Building from scratch is educational, but not scalable.</strong><br> As soon as we want to build even simple perceptron or run on a GPU, we’ll hit a wall.</li> <li> <strong>Hyperparameters matter as much as code.</strong><br> The right settings can make our model look brilliant; the wrong ones can make us question everything.</li> <li> <strong>Frameworks exist for a reason.</strong><br> PyTorch and TensorFlow automate graph construction, GPU support, and much of the tuning process so that we can focus on solving real problems.</li> </ul> <hr> <p><em>In <a href="./2025-06-06-ml-levels-pt-two">Part 2</a>, we’ll see how PyTorch implements neurons to build practical neural networks, using key concepts of computational graphs.</em></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Eli C. McPherson. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/plotly.js@3.0.1/dist/plotly.min.js" integrity="sha256-oy6Be7Eh6eiQFs5M7oXuPxxm9qbJXEtTpfSI93dW16Q=" crossorigin="anonymous"></script> <script defer src="/assets/js/plotly-setup.js?5e81fc889064852664784cb29c0d6970" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>