<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Neural Net Optimization, Part 2 — PyTorch Writ Small | Eli C. McPherson </title> <meta name="author" content="Eli C. McPherson"> <meta name="description" content="The second in a four-part series on neural network optimization, focusing on PyTorch fundamentals, and how at a fundemntal level how pytorch is implemented on a per neruon level."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ecm893.github.io/blog/2025/ml-levels-pt-two/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Neural Net Optimization, Part 2 — PyTorch Writ Small",
            "description": "The second in a four-part series on neural network optimization, focusing on PyTorch fundamentals, and how at a fundemntal level how pytorch is implemented on a per neruon level.",
            "published": "June 06, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Eli</span> C. McPherson </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Neural Net Optimization, Part 2 — PyTorch Writ Small</h1> <p>The second in a four-part series on neural network optimization, focusing on PyTorch fundamentals, and how at a fundemntal level how pytorch is implemented on a per neruon level.</p> </d-title> <d-article> <h1 id="fine-grained-pytorch-what-does-a-neuron-really-learn">Fine-Grained PyTorch: What Does a Neuron Really Learn?</h1> <p>In <a href="./2025-05-23-ml-levels-pt-one">Part 1</a>, we fit a 3rd order polynomial using a hand-built computational graph. Now, let’s see what a single PyTorch neuron can do.</p> <hr> <h2 id="the-single-pytorch-linear-neuron">The Single PyTorch Linear Neuron</h2> <p>A single linear neuron in PyTorch fits functions of the form:</p> \[y = w x + b\] <p>This is just a straight line, a first-order polynomial. No matter how complex your data, a single linear neuron can only learn a line.</p> <p><img src="/assets/img/ml-levels-pt-two/combined_regression.png" alt="Single Neuron Regression Fits"></p> <p><em>Figure: Fitting a sine wave with a single linear neuron.</em></p> <hr> <h2 id="adding-nonlinearity-relu">Adding Nonlinearity: ReLU</h2> <p>Adding a ReLU activation gives us a “kink,” but still only allows for piecewise linear fits:</p> <pre><code class="language-math">f(x) = \max(0, x)
</code></pre> <p><img src="/assets/img/ml-levels-pt-two/combined_regression_relu.png" alt="Single Neuron Regression Fits"></p> <p><em>Figure: Fitting a sine wave with a single ReLU neuron.</em></p> <hr> <h2 id="more-neurons-more-segments">More Neurons, More Segments</h2> <p>What if we used 2 neurons ina hidden layer with ReLU activations? Now we can fit a piecewise linear function with two segments:</p> <details> <summary><strong>Show 2 neurons regression fit</strong></summary> ![Multiple Neurons Regression Fits](/assets/img/ml-levels-pt-two/combined_regression_2n.png) </details> <p>With more neurons, the network can fit more piecewise linear segments, but it still cannot capture smooth curves like a sine wave perfectly, because its fundemntally limited by the linearity of each segment.</p> <hr> <h2 id="key-takeaways">Key Takeaways</h2> <ul> <li> <strong>Single linear neuron:</strong> fits a straight line.</li> <li> <strong>Single ReLU neuron:</strong> fits a line with a kink.</li> <li> <strong>Multiple ReLU neurons:</strong> fit a piecewise linear function.</li> <li> <strong>Generalization:</strong> Even with more neurons, the network struggles to extrapolate or capture smooth nonlinearities outside the training region.</li> </ul> <p>PyTorch builds complexity by stacking simple layers, not by fitting high-order polynomials directly. Understanding these basics helps explain both the power and the limitations of neural networks.</p> <hr> <h2 id="discussion">Discussion</h2> <p>Neural networks are powerful because they combine many simple units. However, each unit has inherent limitations. Understanding these limits is crucial for building intuition about what your models can and cannot learn, and why extrapolation is often unreliable.</p> <p>This highlights some fundamental concepts that are often overlooked in the rush to build complex models:</p> <ol> <li> <p><strong>Piecewise Linear Nature:</strong><br> Neural networks are fundamentally based on piecewise approximations of small linear segments. The more neurons and layers you add, the more complex the piecewise function becomes. However, at each layer, the transformations are still linear in nature. This limitation is important to keep in mind when interpreting the capabilities of your model.</p> </li> <li> <p><strong>Training Range Limitations:</strong><br> Neural networks can only reliably predict values within the range of the data they were trained on. Extrapolation beyond the training data is inherently unreliable. This raises an important question:<br> <em>What is the range of the data when dealing with images, high-dimensional data, or language data?</em><br> Defining the range of such data in a meaningful way is a challenging and often philosophical problem.</p> </li> </ol> <p>While state-of-the-art neural networks can achieve remarkable feats—such as passing a Turing test, it’s important to remember that they are <strong>approximations of the underlying functions they are trying to model</strong>. This has significant implications for how we interpret their outputs and understand their limitations in generalization.</p> <p>(But they are REALLY good approximations!)</p> <hr> <blockquote> <p><strong>Thought Experiment:</strong><br> <em>“If you give an AI enough information about an elephant, does it implicitly know about a cat?”</em><br> — Someone, somewhere on the internet (probably)</p> </blockquote> <p>No.</p> <p>This simple thought experiment underscores the importance of understanding the limitations of neural networks. They do not “know” or “understand” concepts outside the scope of their training data, they approximate patterns within the data they’ve seen.</p> <hr> <p><em>In part 3 we’ll explore how to scale up these concepts with PyTorch Lightning, focusing on abstraction and the ongoing challenge of hyperparameter tuning.</em></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Eli C. McPherson. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>